{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.py loaded\n"
     ]
    }
   ],
   "source": [
    "from utils import * "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning y and var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 4.8063, Val Loss: 3.9391\n",
      "Epoch [100/500], Train Loss: -0.2833, Val Loss: 15.1438\n",
      "Epoch [200/500], Train Loss: -0.6941, Val Loss: 0.1997\n",
      "Epoch [300/500], Train Loss: -0.5084, Val Loss: -0.1482\n",
      "Epoch [400/500], Train Loss: -1.0380, Val Loss: 2.8335\n",
      "Epoch [500/500], Train Loss: -1.6059, Val Loss: 8.3274\n",
      "MAPE test:  5.822160339355468\n"
     ]
    }
   ],
   "source": [
    "output_2_fvc = model_run(file_name = 'FVC', num_epochs= 500, hidden_sizes =  [50,10], output_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[3.1577],\n",
       "         [3.0649],\n",
       "         [3.0660],\n",
       "         [3.5160],\n",
       "         [3.3191]], grad_fn=<ReshapeAliasBackward0>),\n",
       " tensor([[0.0206],\n",
       "         [0.0260],\n",
       "         [0.0344],\n",
       "         [0.0166],\n",
       "         [0.0212]], grad_fn=<ExpBackward0>))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2_fvc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 9.7188, Val Loss: 10.3862\n",
      "Epoch [100/500], Train Loss: 0.0602, Val Loss: 0.0755\n",
      "Epoch [200/500], Train Loss: 0.0487, Val Loss: 0.0833\n",
      "Epoch [300/500], Train Loss: 0.0437, Val Loss: 0.0716\n",
      "Epoch [400/500], Train Loss: 0.0409, Val Loss: 0.0622\n",
      "Epoch [500/500], Train Loss: 0.0390, Val Loss: 0.0571\n",
      "val loss at Epoch :  57\n",
      "MAPE val:  2.8673808574676514\n",
      "MSE val:  0.0171546321362257\n",
      "MAPE test:  7.880953788757324\n",
      "MSE test:  0.06490512192249298\n"
     ]
    }
   ],
   "source": [
    "output_2_fvc = model_run(file_name = 'FVC', num_epochs= 500, hidden_sizes =  [50,10], output_size = 1, type_run = 'without_dataloader')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.8908],\n",
      "        [3.2092],\n",
      "        [3.3516],\n",
      "        [3.4172],\n",
      "        [3.2406]])\n"
     ]
    }
   ],
   "source": [
    "print(output_2_fvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 3.6416, Val Loss: 2.8251\n",
      "Epoch [100/500], Train Loss: -0.0989, Val Loss: 0.1270\n",
      "Epoch [200/500], Train Loss: -0.2612, Val Loss: 0.0592\n",
      "Epoch [300/500], Train Loss: -0.3856, Val Loss: 0.0711\n",
      "Epoch [400/500], Train Loss: -0.1991, Val Loss: -0.0319\n",
      "Epoch [500/500], Train Loss: -0.1635, Val Loss: 0.3311\n",
      "MAPE test:  8.743933010101319\n"
     ]
    }
   ],
   "source": [
    "output_2_fev1 = model_run(file_name = 'FEV1', num_epochs= 500, hidden_sizes =  [50,10], output_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.6659],\n",
       "         [2.7566],\n",
       "         [3.1802],\n",
       "         [3.3837],\n",
       "         [3.2814]], grad_fn=<ReshapeAliasBackward0>),\n",
       " tensor([[0.0691],\n",
       "         [0.0550],\n",
       "         [0.0106],\n",
       "         [0.0042],\n",
       "         [0.0175]], grad_fn=<ExpBackward0>))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2_fev1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 8.3993, Val Loss: 6.4152\n",
      "Epoch [100/500], Train Loss: 0.0608, Val Loss: 0.1169\n",
      "Epoch [200/500], Train Loss: 0.0456, Val Loss: 0.0713\n",
      "Epoch [300/500], Train Loss: 0.0639, Val Loss: 0.1187\n",
      "Epoch [400/500], Train Loss: 0.0296, Val Loss: 0.0501\n",
      "Epoch [500/500], Train Loss: 0.0121, Val Loss: 0.0578\n",
      "MAPE test:  7.843387603759766\n"
     ]
    }
   ],
   "source": [
    "output_1_fvc = model_run(file_name = 'FVC', num_epochs= 500, hidden_sizes =  [50,10], output_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.8671],\n",
       "        [3.2058],\n",
       "        [3.3606],\n",
       "        [3.3911],\n",
       "        [3.2314]], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1_fvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 5.1707, Val Loss: 3.9330\n",
      "Epoch [100/500], Train Loss: 0.0143, Val Loss: 0.0693\n",
      "Epoch [200/500], Train Loss: 0.0115, Val Loss: 0.1103\n",
      "Epoch [300/500], Train Loss: 0.0049, Val Loss: 0.1963\n",
      "Epoch [400/500], Train Loss: 0.0038, Val Loss: 0.1802\n",
      "Epoch [500/500], Train Loss: 0.0031, Val Loss: 0.1809\n",
      "MAPE test:  7.96909236907959\n"
     ]
    }
   ],
   "source": [
    "output_1_fev1 = model_run(file_name = 'FEV1', num_epochs= 500, hidden_sizes =  [50,10], output_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6579],\n",
       "        [2.4321],\n",
       "        [3.0536],\n",
       "        [3.3141],\n",
       "        [3.1089]], grad_fn=<ReshapeAliasBackward0>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1_fev1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"hidden_size\": tune.choice([[50,10] ,[60,30,5], [75,35,15,5],[128,80,50,30,16]]),\n",
    "    'lr':tune.choice([0.01, 0.001]),\n",
    "    \"num_epochs\": tune.choice([2000])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config_fvc_out2 = {'hidden_size': [75, 35, 15, 5], 'lr': 0.001, 'num_epochs': 500}\n",
    "best_config_fev1_out2 = {'hidden_size': [75, 35, 15, 5], 'lr': 0.01, 'num_epochs': 500}\n",
    "best_config_fvc_out1 = {'hidden_size': [60, 30, 5], 'lr': 0.01, 'num_epochs': 500}        \n",
    "best_config_fev1_out1 = {'hidden_size': [128, 80, 50, 30, 16], 'lr': 0.001, 'num_epochs': 500}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 7.5943, Val Loss: 8.1030\n",
      "Epoch [100/500], Train Loss: -0.0895, Val Loss: 4.3815\n",
      "Epoch [200/500], Train Loss: -0.1199, Val Loss: 6.2287\n",
      "Epoch [300/500], Train Loss: -0.1957, Val Loss: 8.5090\n",
      "Epoch [400/500], Train Loss: -0.1763, Val Loss: 15.6482\n",
      "Epoch [500/500], Train Loss: -0.2335, Val Loss: 14.4548\n",
      "MAPE test:  7.058881950378418\n"
     ]
    }
   ],
   "source": [
    "output_2_fvc = model_run(file_name = 'FVC', num_epochs= best_config_fvc_out2['num_epochs'], hidden_sizes =  best_config_fvc_out2['hidden_size'], output_size = 2, lr = best_config_fvc_out2['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 4.1476, Val Loss: 2.6850\n",
      "Epoch [100/500], Train Loss: 0.0832, Val Loss: 0.2637\n",
      "Epoch [200/500], Train Loss: 0.0672, Val Loss: 0.1609\n",
      "Epoch [300/500], Train Loss: -0.0993, Val Loss: 0.2762\n",
      "Epoch [400/500], Train Loss: -0.2233, Val Loss: 0.6341\n",
      "Epoch [500/500], Train Loss: -0.2244, Val Loss: 0.3012\n",
      "MAPE test:  6.837859439849853\n"
     ]
    }
   ],
   "source": [
    "output_2_fev1 = model_run(file_name = 'FEV1', num_epochs= best_config_fev1_out2['num_epochs'], hidden_sizes =  best_config_fev1_out2['hidden_size'], output_size = 2, lr = best_config_fev1_out2['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 8.1137, Val Loss: 5.2728\n",
      "Epoch [100/500], Train Loss: 0.0467, Val Loss: 0.0939\n",
      "Epoch [200/500], Train Loss: 0.0421, Val Loss: 0.0812\n",
      "Epoch [300/500], Train Loss: 0.0398, Val Loss: 0.1245\n",
      "Epoch [400/500], Train Loss: 0.0341, Val Loss: 0.1738\n",
      "Epoch [500/500], Train Loss: 0.0169, Val Loss: 0.0595\n",
      "MAPE test:  8.42601375579834\n"
     ]
    }
   ],
   "source": [
    "output_1_fvc = model_run(file_name = 'FVC', num_epochs= best_config_fvc_out1['num_epochs'], hidden_sizes =  best_config_fvc_out1['hidden_size'], output_size = 1, lr = best_config_fvc_out1['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 7.6587, Val Loss: 7.7153\n",
      "Epoch [100/500], Train Loss: 0.0245, Val Loss: 0.0559\n",
      "Epoch [200/500], Train Loss: 0.0109, Val Loss: 0.0787\n",
      "Epoch [300/500], Train Loss: 0.0098, Val Loss: 0.0836\n",
      "Epoch [400/500], Train Loss: 0.0083, Val Loss: 0.1129\n",
      "Epoch [500/500], Train Loss: 0.0032, Val Loss: 0.1093\n",
      "MAPE test:  9.896806907653808\n"
     ]
    }
   ],
   "source": [
    "output_1_fev1 = model_run(file_name = 'FEV1', num_epochs= best_config_fev1_out1['num_epochs'], hidden_sizes =  best_config_fev1_out1['hidden_size'], output_size = 1, lr = best_config_fev1_out1['lr'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fvc output 2\n",
    "# MAPE test:  5.872068405151367\n",
    "# tune:\n",
    "# MAPE test:  5.188878536224365\n",
    "\n",
    "\n",
    "# fev1 output 2\n",
    "# MAPE test:  10.863091468811035\n",
    "# tune :\n",
    "# MAPE test:  10.298738479614258\n",
    "\n",
    "\n",
    "# fvc output 1\n",
    "# MAPE test:  8.039169311523438\n",
    "# tune:\n",
    "# MAPE test:  5.899529457092285\n",
    "\n",
    "\n",
    "# fev1 output 1\n",
    "# MAPE test:  9.542654991149902\n",
    "# tune:\n",
    "# MAPE test:  9.465457916259766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>hostname       </th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mlp_102d9_00000</td><td>2023-05-04_09-44-11</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 3380</td><td style=\"text-align: right;\"> 1683173651</td><td>102d9_00000</td></tr>\n",
       "<tr><td>train_mlp_102d9_00001</td><td>2023-05-04_09-44-29</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\">22868</td><td style=\"text-align: right;\"> 1683173669</td><td>102d9_00001</td></tr>\n",
       "<tr><td>train_mlp_102d9_00002</td><td>2023-05-04_09-44-44</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\">14740</td><td style=\"text-align: right;\"> 1683173684</td><td>102d9_00002</td></tr>\n",
       "<tr><td>train_mlp_102d9_00003</td><td>2023-05-04_09-44-59</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 6188</td><td style=\"text-align: right;\"> 1683173699</td><td>102d9_00003</td></tr>\n",
       "<tr><td>train_mlp_102d9_00004</td><td>2023-05-04_09-45-17</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\">15876</td><td style=\"text-align: right;\"> 1683173717</td><td>102d9_00004</td></tr>\n",
       "<tr><td>train_mlp_102d9_00005</td><td>2023-05-04_09-45-44</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 8408</td><td style=\"text-align: right;\"> 1683173744</td><td>102d9_00005</td></tr>\n",
       "<tr><td>train_mlp_102d9_00006</td><td>2023-05-04_09-46-20</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\">  372</td><td style=\"text-align: right;\"> 1683173780</td><td>102d9_00006</td></tr>\n",
       "<tr><td>train_mlp_102d9_00007</td><td>2023-05-04_09-46-50</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\">18232</td><td style=\"text-align: right;\"> 1683173810</td><td>102d9_00007</td></tr>\n",
       "<tr><td>train_mlp_102d9_00008</td><td>2023-05-04_09-47-23</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 6276</td><td style=\"text-align: right;\"> 1683173843</td><td>102d9_00008</td></tr>\n",
       "<tr><td>train_mlp_102d9_00009</td><td>2023-05-04_09-47-23</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\">20704</td><td style=\"text-align: right;\"> 1683173843</td><td>102d9_00009</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_mlp_102d9_00000, train_mlp_102d9_00001, train_mlp_102d9_00002, train_mlp_102d9_00003, train_mlp_102d9_00004, train_mlp_102d9_00005, train_mlp_102d9_00006, train_mlp_102d9_00007, train_mlp_102d9_00008, train_mlp_102d9_00009])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8b6e00c76010>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0manalysis_fvc_out1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraytune_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'FVC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\iitgn\\Thesis\\Spiro_Mask2\\utils.py\u001b[0m in \u001b[0;36mraytune_fun\u001b[1;34m(output_size, file_name)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Initialize Ray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     analysis = tune.run(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mtrain_mlp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ray\\tune\\tune.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, trial_executor, _experiment_checkpoint_dir, _remote, _remote_string_queue, _tuner_api)\u001b[0m\n\u001b[0;32m    937\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexperiment_interrupted_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 939\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trials did not complete\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    940\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trials did not complete: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTuneError\u001b[0m: ('Trials did not complete', [train_mlp_102d9_00000, train_mlp_102d9_00001, train_mlp_102d9_00002, train_mlp_102d9_00003, train_mlp_102d9_00004, train_mlp_102d9_00005, train_mlp_102d9_00006, train_mlp_102d9_00007, train_mlp_102d9_00008, train_mlp_102d9_00009])"
     ]
    }
   ],
   "source": [
    "analysis_fvc_out1 = raytune_fun(output_size = 1, file_name='FVC') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config_fvc = analysis_fvc_out1.get_best_config(metric=\"val_loss\", mode=\"min\")\n",
    "print(\"Best config:\", best_config_fvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th>date               </th><th>done  </th><th>experiment_tag                    </th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mlp_output_1_6614e_00000</td><td>2023-05-03_23-30-49</td><td>True  </td><td>0_hidden_size=75_35_15_5,lr=0.0100</td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">21600</td><td style=\"text-align: right;\">           0.512657 </td><td style=\"text-align: right;\">         0.512657 </td><td style=\"text-align: right;\">     0.512657 </td><td style=\"text-align: right;\"> 1683136849</td><td style=\"text-align: right;\">                   1</td><td>6614e_00000</td><td style=\"text-align: right;\">   11.1893</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00001</td><td>2023-05-03_23-31-02</td><td>True  </td><td>1_hidden_size=75_35_15_5,lr=0.0100</td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">14260</td><td style=\"text-align: right;\">           0.0180161</td><td style=\"text-align: right;\">         0.0180161</td><td style=\"text-align: right;\">     0.0180161</td><td style=\"text-align: right;\"> 1683136862</td><td style=\"text-align: right;\">                   1</td><td>6614e_00001</td><td style=\"text-align: right;\">   11.1893</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00002</td><td>2023-05-03_23-31-14</td><td>True  </td><td>2_hidden_size=75_35_15_5,lr=0.0100</td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 1924</td><td style=\"text-align: right;\">           0.0215249</td><td style=\"text-align: right;\">         0.0215249</td><td style=\"text-align: right;\">     0.0215249</td><td style=\"text-align: right;\"> 1683136874</td><td style=\"text-align: right;\">                   1</td><td>6614e_00002</td><td style=\"text-align: right;\">   11.1893</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00003</td><td>2023-05-03_23-31-29</td><td>True  </td><td>3_hidden_size=50,lr=0.0100        </td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 3468</td><td style=\"text-align: right;\">           0.0140045</td><td style=\"text-align: right;\">         0.0140045</td><td style=\"text-align: right;\">     0.0140045</td><td style=\"text-align: right;\"> 1683136889</td><td style=\"text-align: right;\">                   1</td><td>6614e_00003</td><td style=\"text-align: right;\">   10.8933</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00004</td><td>2023-05-03_23-31-45</td><td>True  </td><td>4_hidden_size=75_35_15_5,lr=0.0100</td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">16884</td><td style=\"text-align: right;\">           0.0279961</td><td style=\"text-align: right;\">         0.0279961</td><td style=\"text-align: right;\">     0.0279961</td><td style=\"text-align: right;\"> 1683136905</td><td style=\"text-align: right;\">                   1</td><td>6614e_00004</td><td style=\"text-align: right;\">   11.1893</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00005</td><td>2023-05-03_23-31-59</td><td>True  </td><td>5_hidden_size=50_10,lr=0.0100     </td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 1372</td><td style=\"text-align: right;\">           0.0244927</td><td style=\"text-align: right;\">         0.0244927</td><td style=\"text-align: right;\">     0.0244927</td><td style=\"text-align: right;\"> 1683136919</td><td style=\"text-align: right;\">                   1</td><td>6614e_00005</td><td style=\"text-align: right;\">   10.3862</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00006</td><td>2023-05-03_23-32-16</td><td>True  </td><td>6_hidden_size=60_30_5,lr=0.0100   </td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 7308</td><td style=\"text-align: right;\">           0.0174947</td><td style=\"text-align: right;\">         0.0174947</td><td style=\"text-align: right;\">     0.0174947</td><td style=\"text-align: right;\"> 1683136936</td><td style=\"text-align: right;\">                   1</td><td>6614e_00006</td><td style=\"text-align: right;\">   10.7365</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00007</td><td>2023-05-03_23-32-31</td><td>True  </td><td>7_hidden_size=50_10,lr=0.0100     </td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">22232</td><td style=\"text-align: right;\">           0.0175302</td><td style=\"text-align: right;\">         0.0175302</td><td style=\"text-align: right;\">     0.0175302</td><td style=\"text-align: right;\"> 1683136951</td><td style=\"text-align: right;\">                   1</td><td>6614e_00007</td><td style=\"text-align: right;\">   10.3862</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00008</td><td>2023-05-03_23-32-32</td><td>True  </td><td>8_hidden_size=50,lr=0.0001        </td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">21600</td><td style=\"text-align: right;\">           0.0139904</td><td style=\"text-align: right;\">         0.0139904</td><td style=\"text-align: right;\">     0.0139904</td><td style=\"text-align: right;\"> 1683136952</td><td style=\"text-align: right;\">                   1</td><td>6614e_00008</td><td style=\"text-align: right;\">   12.3452</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00009</td><td>2023-05-03_23-32-32</td><td>True  </td><td>9_hidden_size=60_30_5,lr=0.0100   </td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">14260</td><td style=\"text-align: right;\">           0.0145195</td><td style=\"text-align: right;\">         0.0145195</td><td style=\"text-align: right;\">     0.0145195</td><td style=\"text-align: right;\"> 1683136952</td><td style=\"text-align: right;\">                   1</td><td>6614e_00009</td><td style=\"text-align: right;\">   10.0083</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 23:32:32,985\tINFO tune.py:945 -- Total run time: 119.70 seconds (119.46 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-03 23:32:32 (running for 00:01:59.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/8 CPUs, 0/1 GPUs\n",
      "Result logdir: C:\\Users\\HP\\ray_results\\train_mlp_output_1_2023-05-03_23-30-33\n",
      "Number of trials: 10/10 (10 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+-----------------+--------+--------+------------------+------------+\n",
      "| Trial name                     | status     | loc             | hidden_size     |     lr |   iter |   total time (s) |   val_loss |\n",
      "|--------------------------------+------------+-----------------+-----------------+--------+--------+------------------+------------|\n",
      "| train_mlp_output_1_6614e_00000 | TERMINATED | 127.0.0.1:21600 | [75, 35, 15, 5] | 0.01   |      1 |        0.512657  |    11.1893 |\n",
      "| train_mlp_output_1_6614e_00001 | TERMINATED | 127.0.0.1:14260 | [75, 35, 15, 5] | 0.01   |      1 |        0.0180161 |    11.1893 |\n",
      "| train_mlp_output_1_6614e_00002 | TERMINATED | 127.0.0.1:1924  | [75, 35, 15, 5] | 0.01   |      1 |        0.0215249 |    11.1893 |\n",
      "| train_mlp_output_1_6614e_00003 | TERMINATED | 127.0.0.1:3468  | [50]            | 0.01   |      1 |        0.0140045 |    10.8933 |\n",
      "| train_mlp_output_1_6614e_00004 | TERMINATED | 127.0.0.1:16884 | [75, 35, 15, 5] | 0.01   |      1 |        0.0279961 |    11.1893 |\n",
      "| train_mlp_output_1_6614e_00005 | TERMINATED | 127.0.0.1:1372  | [50, 10]        | 0.01   |      1 |        0.0244927 |    10.3862 |\n",
      "| train_mlp_output_1_6614e_00006 | TERMINATED | 127.0.0.1:7308  | [60, 30, 5]     | 0.01   |      1 |        0.0174947 |    10.7365 |\n",
      "| train_mlp_output_1_6614e_00007 | TERMINATED | 127.0.0.1:22232 | [50, 10]        | 0.01   |      1 |        0.0175302 |    10.3862 |\n",
      "| train_mlp_output_1_6614e_00008 | TERMINATED | 127.0.0.1:21600 | [50]            | 0.0001 |      1 |        0.0139904 |    12.3452 |\n",
      "| train_mlp_output_1_6614e_00009 | TERMINATED | 127.0.0.1:14260 | [60, 30, 5]     | 0.01   |      1 |        0.0145195 |    10.0083 |\n",
      "+--------------------------------+------------+-----------------+-----------------+--------+--------+------------------+------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "analysis_fvc = tune.run( train_mlp_output_1,\n",
    "            config=config,\n",
    "            num_samples=10,\n",
    "            progress_reporter=tune.CLIReporter()\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config: {'hidden_size': [60, 30, 5], 'lr': 0.01}\n"
     ]
    }
   ],
   "source": [
    "best_config_fvc = analysis_fvc.get_best_config(metric=\"val_loss\", mode=\"min\")\n",
    "print(\"Best config:\", best_config_fvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load data correspoding to PEF, FEV1, FVC\n",
    "X = np.load('Spiro_Mask_dataset/FVC_FEATURES_60.npy')\n",
    "Y = np.load('Spiro_Mask_dataset/FVC_LABELS_60.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_set = np.delete(X,[23,55,4,9,52,44,45,33,43,20,1,50], axis=0) \n",
    "all_labels = np.delete(Y,[23,55,4,9,52,44,45,33,43,20,1,50], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MPE is = 6.048729090522371\n"
     ]
    }
   ],
   "source": [
    "#LOOCV ONLY\n",
    "#All left out samples\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "#store the predictions here\n",
    "FVC_predictions = []\n",
    "\n",
    "\n",
    "regressor = RandomForestRegressor(n_jobs=-1, bootstrap=True, criterion='mae', \n",
    "                                  n_estimators=100,  max_features='auto', max_depth=300,  \n",
    "                                  min_samples_leaf=1,min_samples_split=5,random_state=42)\n",
    "\n",
    "# Create a based model\n",
    "mpeList = []\n",
    "for train_index, test_index in loo.split(all_set):\n",
    "    #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = all_set[train_index], all_set[test_index]\n",
    "    y_train, y_test = all_labels[train_index], all_labels[test_index]\n",
    "\n",
    "    \n",
    "\n",
    "    #for RF and SVR\n",
    "    reg = regressor.fit(X_train, y_train)\n",
    "    pred = reg.predict(X_test)\n",
    "    \n",
    "    FVC_predictions.append(pred[0])\n",
    "    \n",
    "   \n",
    "    \n",
    "    #print(\"True FVC = {}, Predicted FVC = {}\".format(y_test,pred))\n",
    "    mpe = 100*np.mean(np.abs((y_test.reshape(-1) -pred)/y_test.reshape(-1)))\n",
    "    mpeList.append(mpe)\n",
    "    #print(\"Error on Participant ID {} is {:2f}\".format(test_index,mpe))\n",
    "    #print(\"\\n\")\n",
    "print(\"Overall MPE is = {}\".format(np.mean(mpeList)))\n",
    "#print(\"Bootstrap = {},Depth = {}, Features = {}, Leaf = {}, Split = {}, Estimator = {}\".format(bootstrap,depth,features,leaf,split,estimator))\n",
    "\n",
    "FVC_predictions = np.array(FVC_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MAPE is = 6.772241273401555\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "# from sklearn.ensemble import XGBRegressor\n",
    "\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Store the predictions here\n",
    "FVC_predictions = []\n",
    "\n",
    "# Instantiate the regressor\n",
    "regressor = XGBRegressor(n_jobs=-1, objective='reg:squarederror', random_state=42)\n",
    "\n",
    "# Create a list to store the mean absolute percentage error (MAPE)\n",
    "mape_list = []\n",
    "\n",
    "for train_index, test_index in loo.split(all_set):\n",
    "    X_train, X_test = all_set[train_index], all_set[test_index]\n",
    "    y_train, y_test = all_labels[train_index], all_labels[test_index]\n",
    "\n",
    "    # Fit the XGBoost model\n",
    "    reg = regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the left-out sample\n",
    "    pred = reg.predict(X_test)\n",
    "    \n",
    "    FVC_predictions.append(pred[0])\n",
    "\n",
    "    # Calculate the mean absolute percentage error (MAPE)\n",
    "    mape = 100 * np.mean(np.abs((y_test.reshape(-1) - pred) / y_test.reshape(-1)))\n",
    "    mape_list.append(mape)\n",
    "\n",
    "# Calculate the overall mean MAPE\n",
    "overall_mape = np.mean(mape_list)\n",
    "print(\"Overall MAPE is =\", overall_mape)\n",
    "\n",
    "# Convert FVC_predictions to a numpy array\n",
    "FVC_predictions = np.array(FVC_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1280059814453125,\n",
       " 5.317711069228796,\n",
       " 4.039182534088961,\n",
       " 0.6196285116261466,\n",
       " 4.346701027690505,\n",
       " 1.7515261967976863,\n",
       " 15.763404634263784,\n",
       " 7.55563551379788,\n",
       " 11.63446729983425,\n",
       " 0.05322294664217509,\n",
       " 9.532654285430903,\n",
       " 15.366975691140775,\n",
       " 3.018192338794933,\n",
       " 1.585559013105257,\n",
       " 1.288686960171427,\n",
       " 2.712267484420382,\n",
       " 6.403219933603323,\n",
       " 1.8887930278536684,\n",
       " 21.220452955153107,\n",
       " 4.654681298040572,\n",
       " 0.46853261278165154,\n",
       " 0.00769144449478199,\n",
       " 15.741674783753181,\n",
       " 7.075235609374293,\n",
       " 20.983485934100568,\n",
       " 0.33367012120500844,\n",
       " 5.099932352701822,\n",
       " 2.8466869044948244,\n",
       " 26.82919187365838,\n",
       " 18.57961101352044,\n",
       " 2.507450024990209,\n",
       " 0.23117853125288437,\n",
       " 5.04556713682232,\n",
       " 25.598946943977808,\n",
       " 2.0692673740008014,\n",
       " 3.876606061144278,\n",
       " 5.2677976356825305,\n",
       " 5.468972640879007,\n",
       " 15.08385924731983,\n",
       " 3.6811694246796756,\n",
       " 8.149854587935085,\n",
       " 0.26177565256754554,\n",
       " 2.826091484241543,\n",
       " 3.0244695412001006,\n",
       " 8.974993298625385,\n",
       " 3.8660317136530273,\n",
       " 8.709634434093124,\n",
       " 2.5772340369946978]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mape_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.0338402, 3.560054 , 3.0795598, 3.2097661, 3.3000388, 3.663055 ,\n",
       "       3.0325174, 3.3342247, 3.226236 , 2.8915381, 3.505045 , 3.2922246,\n",
       "       3.113116 , 3.2608964, 3.160207 , 3.2046227, 3.2559385, 3.1003141,\n",
       "       3.236586 , 3.2442951, 3.0058503, 3.12024  , 2.763673 , 3.2151968,\n",
       "       3.8230782, 3.149456 , 3.152998 , 3.4247947, 3.1024423, 3.4522245,\n",
       "       3.3049974, 3.382163 , 3.1334963, 3.7930882, 3.0824919, 3.2305624,\n",
       "       3.2738285, 2.868756 , 3.130281 , 3.017122 , 3.1471608, 2.9921467,\n",
       "       3.0221086, 3.015939 , 3.1130552, 3.2877817, 3.012582 , 3.2149513],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FVC_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(FVC_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall MAPE is = 6.613657490460166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "# Store the predictions here\n",
    "FVC_predictions = []\n",
    "# Instantiate the SVR model\n",
    "# regressor = SVR(kernel='rbf', C=1.0, epsilon=0.1)\n",
    "regressor = SVR(kernel='rbf', C=10, gamma=10, epsilon=.1)\n",
    "# Create a list to store the mean absolute percentage error (MAPE)\n",
    "mape_list = []\n",
    "\n",
    "for train_index, test_index in loo.split(all_set):\n",
    "    X_train, X_test = all_set[train_index], all_set[test_index]\n",
    "    y_train, y_test = all_labels[train_index], all_labels[test_index]\n",
    "\n",
    "    # Fit the SVR model\n",
    "    reg = regressor.fit(X_train, y_train)\n",
    "    \n",
    "    # Make predictions on the left-out sample\n",
    "    pred = reg.predict(X_test)\n",
    "    \n",
    "    FVC_predictions.append(pred[0])\n",
    "\n",
    "    # Calculate the mean absolute percentage error (MAPE)\n",
    "    mape = 100 * np.mean(np.abs((y_test.reshape(-1) - pred) / y_test.reshape(-1)))\n",
    "    mape_list.append(mape)\n",
    "\n",
    "# Calculate the overall mean MAPE\n",
    "overall_mape = np.mean(mape_list)\n",
    "print(\"Overall MAPE is =\", overall_mape)\n",
    "\n",
    "# Convert FVC_predictions to a numpy array\n",
    "FVC_predictions = np.array(FVC_predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7576, 0.2793, 0.4031]])\n",
      "tensor([[0.7347, 0.0293, 0.7999]])\n"
     ]
    }
   ],
   "source": [
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n",
    "print(torch.rand(1,3))\n",
    "\n",
    "print(torch.rand(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7576, 0.2793, 0.4031]])\n",
      "tensor([[0.7576, 0.2793, 0.4031]])\n"
     ]
    }
   ],
   "source": [
    "random_seed = 1\n",
    "torch.manual_seed(random_seed)\n",
    "print(torch.rand(1,3))\n",
    "torch.manual_seed(random_seed)\n",
    "print(torch.rand(1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4550, 0.5725, 0.4980]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7576, 0.2793, 0.4031]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(random_seed)\n",
    "torch.rand(1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For :  Random_Forrest_Regression\n",
      " rogress : 1/48Progress : 2/48Progress : 3/48Progress : 4/48Progress : 5/48Progress : 6/48Progress : 7/48Progress : 8/48Progress : 9/48Progress : 10/48Progress : 11/48Progress : 12/48Progress : 13/48Progress : 14/48Progress : 15/48Progress : 16/48Progress : 17/48Progress : 18/48Progress : 19/48Progress : 20/48Progress : 21/48Progress : 22/48Progress : 23/48Progress : 24/48Progress : 25/48Progress : 26/48Progress : 27/48Progress : 28/48Progress : 29/48Progress : 30/48Progress : 31/48Progress : 32/48Progress : 33/48Progress : 34/48Progress : 35/48Progress : 36/48Progress : 37/48Progress : 38/48Progress : 39/48Progress : 40/48Progress : 41/48Progress : 42/48Progress : 43/48Progress : 44/48Progress : 45/48Progress : 46/48Progress : 47/48Progress : 48/48"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-3b3b6e6ec624>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     78\u001b[0m     \u001b[1;31m# print(\"Calculated MAPE : \", MAPE )\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;31m# print(\"Calculated MAPE_func : \", MAPE_func(y_GT,y_PT))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 80\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" sklearm MAPE : \"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m100\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_GT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_PT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     81\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" sklearm MAE : \"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_GT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_PT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     82\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" sklearm MSE : \"\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_GT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_PT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'numpy.float64' object is not callable"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut, KFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "# from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading npy data.\n",
    "X = np.load(\"Spiro_Mask_dataset/FEV1_FEATURES_60.npy\")\n",
    "y = np.load(\"Spiro_Mask_dataset/FEV1_LABELS_60.npy\")\n",
    "\n",
    "X= pd.DataFrame(np.delete(X,[23,55,4,9,52,44,45,33,43,20,1,50],axis=0))\n",
    "y= pd.DataFrame(np.delete(y,[23,55,4,9,52,44,45,33,43,20,1,50],axis=0))\n",
    "\n",
    "# Instantiating Random forrest Regressor.\n",
    "RF = RandomForestRegressor( n_jobs=-1, bootstrap=True, criterion='mae', \n",
    "                                  n_estimators=500,  max_features=1.0, max_depth=300,  \n",
    "                                  min_samples_leaf=1, min_samples_split=5 ,random_state=42)\n",
    "\n",
    "# Instantiating Decision Tree Regressor.\n",
    "DT = DecisionTreeRegressor( criterion='absolute_error',min_samples_leaf=1, \n",
    "                                min_samples_split=5 ,random_state=42)\n",
    "\n",
    "# Instantiating Linear Regressor.\n",
    "LR = LinearRegression()\n",
    "\n",
    "# Estimator/Regressor Dictionary.\n",
    "RegDict = { \"Random_Forrest_Regression\" :   RF,\n",
    "            \"Decision_Tree_Regression\" :    DT,\n",
    "            \"Linear_Regression\":            LR }\n",
    "\n",
    "tot = len(X)\n",
    "# Instantiating Leave_One_Out split function.\n",
    "loo = LeaveOneOut()\n",
    "\n",
    "def MAPE_func(y_true,y_pred):\n",
    "    abserr = np.zeros(len(y_true))\n",
    "    for i in range(len(y_true)):\n",
    "        abserr[i] = np.abs( (y_true[i] - y_pred[i]) / y_true[i])\n",
    "    return 100 * np.mean(abserr)\n",
    "\n",
    "\n",
    "# We run for every Regressor.\n",
    "for Reg in RegDict:\n",
    "\n",
    "    print(\"For : \",Reg)\n",
    "    Model = RegDict[Reg]\n",
    "    prog = 0\n",
    "    y_GT = []\n",
    "    y_PT = []\n",
    "    abserror=[]\n",
    "\n",
    "    # For every split obtained by Leave_One_Out split function.\n",
    "    for i,(train_index, test_index) in enumerate(loo.split(X)):\n",
    "\n",
    "\n",
    "\n",
    "        #m To show some sort of progress.\n",
    "        prog = prog + 1\n",
    "        print(\"Progress : {0}/{1}\\r\".format(prog,tot),end=\" \")\n",
    "\n",
    "        # Test-train split for the fold.\n",
    "        X_Train, X_Test = X.iloc[train_index],X.iloc[test_index]\n",
    "        y_Train, y_Test = y.iloc[train_index],y.iloc[test_index]\n",
    "        \n",
    "        Model.fit(X_Train, np.ravel(y_Train))\n",
    "        pred = Model.predict(X_Test)  \n",
    "\n",
    "        y_GT.append(y_Test.iloc[0,0])\n",
    "        y_PT.append(pred[0]) \n",
    " \n",
    "        abserror.append(np.abs( (y_Test.iloc[0,0] - pred[0])/ y_Test.iloc[0,0] ))\n",
    "\n",
    "\n",
    "    # Calculating Metrics\n",
    "    MAPE = 100 * np.mean(abserror)\n",
    "    # print(\"Calculated MAPE : \", MAPE )\n",
    "    # print(\"Calculated MAPE_func : \", MAPE_func(y_GT,y_PT))\n",
    "    print(\" sklearm MAPE : \" , 100 * mape(y_GT,y_PT))\n",
    "    print(\" sklearm MAE : \" , mean_absolute_error(y_GT,y_PT))\n",
    "    print(\" sklearm MSE : \" , mean_squared_error(y_GT,y_PT))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "virtual_environment_name",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1a377f81425412115e3f1878e4306705aed019f0a124c20f9ac8eef42d28dc35"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
