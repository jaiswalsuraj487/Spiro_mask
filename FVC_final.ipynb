{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import ray\n",
    "from ray import tune\n",
    "import torch.nn as nn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38, 155]) torch.Size([38, 1])\n",
      "torch.Size([5, 155]) torch.Size([5, 1])\n",
      "torch.Size([5, 155]) torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train,X_val, X_test, y_train, y_val, y_test = load_data('FVC')\n",
    "# print(X.shape, Y.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38, 1]) torch.Size([38, 1])\n",
      "torch.Size([38]) torch.Size([38])\n",
      "torch.Size([38, 1]) torch.Size([38, 1])\n",
      "Epoch [1/1], Train Loss: 9.7188, Val Loss: 10.3862\n",
      "val_loss 10.386189460754395\n",
      "MSE Test Loss: 8.4290\n",
      "MAPE Test Loss: 94.6442\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Define model, loss function, and optimizer\n",
    "model = MLP(input_size=X_train.shape[1], hidden_sizes=[50,10], output_size=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Train and validate the model\n",
    "num_epochs = 1\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "ep =0\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "\n",
    "    outputs = model(X_train)\n",
    "    # outputs = outputs[:, 0].reshape(-1,1)\n",
    "    print(outputs.shape, y_train.shape)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # train_losses.append(loss.item())\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val)\n",
    "        val_loss = criterion(outputs, y_val)\n",
    "        # val_losses.append(loss.item())\n",
    "\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            ep = epoch\n",
    "            torch.save(model.state_dict(), 'best_model.pt') \n",
    "\n",
    "    if (epoch+1 ==1) or (epoch+1) % 500 == 0:\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item(), val_loss.item()))\n",
    "\n",
    "# Evaluate \n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print('val_loss', criterion(model(X_val), y_val).item())\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test)\n",
    "    print('MSE Test Loss: {:.4f}'.format(test_loss.item()))\n",
    "    print('MAPE Test Loss: {:.4f}'.format(mape_loss(y_pred, y_test).item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04501364752650261"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "def train_mlp(config, checkpoint_dir=None):\n",
    "    X_train,X_val, X_test, y_train, y_val, y_test = load_data('FVC')\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    model = MLP(input_size=X_train.shape[1], hidden_sizes=config[\"hidden_size\"], output_size=1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    num_epochs = 500\n",
    "    for epoch in range(num_epochs):\n",
    "      # Training\n",
    "      model.train()\n",
    "      outputs = model(X_train)\n",
    "      loss = criterion(outputs, y_train)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      tune.report(loss=loss.item())\n",
    "      # Validation\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "            outputs = model(X_val)\n",
    "            val_loss = criterion(outputs, y_val)\n",
    "            if val_loss.item() < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "\n",
    "      # tune.report(val_loss = best_val_loss)\n",
    "      tune.report(val_loss = val_loss.item())\n",
    "      # tune.report(best_val_loss = best_val_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 14:56:51,232\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "2023-04-26 14:56:52,119\tWARNING callback.py:142 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-04-26 14:56:54 (running for 00:00:02.79)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 0/2 GPUs\n",
      "Result logdir: /home/akbar/ray_results/train_mlp_2023-04-26_14-56-52\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+-----------------------+----------+--------------------+-----------------+-------+\n",
      "| Trial name            | status   | loc                | hidden_size     |    lr |\n",
      "|-----------------------+----------+--------------------+-----------------+-------|\n",
      "| train_mlp_7a547_00000 | RUNNING  | 10.7.44.21:1033366 | [75, 35, 15, 5] | 0.001 |\n",
      "| train_mlp_7a547_00001 | PENDING  |                    | [75, 35, 15, 5] | 0.01  |\n",
      "| train_mlp_7a547_00002 | PENDING  |                    | [75, 35, 15, 5] | 0.01  |\n",
      "| train_mlp_7a547_00003 | PENDING  |                    | [50, 10]        | 0.01  |\n",
      "| train_mlp_7a547_00004 | PENDING  |                    | [50]            | 0.005 |\n",
      "| train_mlp_7a547_00005 | PENDING  |                    | [75, 35, 15, 5] | 0.005 |\n",
      "| train_mlp_7a547_00006 | PENDING  |                    | [75, 35, 15, 5] | 0.01  |\n",
      "| train_mlp_7a547_00007 | PENDING  |                    | [50, 10]        | 0.01  |\n",
      "| train_mlp_7a547_00008 | PENDING  |                    | [60, 30, 5]     | 0.001 |\n",
      "| train_mlp_7a547_00009 | PENDING  |                    | [75, 35, 15, 5] | 0.005 |\n",
      "+-----------------------+----------+--------------------+-----------------+-------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>done  </th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th style=\"text-align: right;\">   loss</th><th>node_ip   </th><th style=\"text-align: right;\">    pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mlp_7a547_00000</td><td>2023-04-26_14-56-54</td><td>False </td><td>cvig      </td><td style=\"text-align: right;\">                         1</td><td style=\"text-align: right;\">10.2943</td><td>10.7.44.21</td><td style=\"text-align: right;\">1033366</td><td style=\"text-align: right;\">           0.0610158</td><td style=\"text-align: right;\">         0.0610158</td><td style=\"text-align: right;\">     0.0610158</td><td style=\"text-align: right;\"> 1682501214</td><td style=\"text-align: right;\">                   1</td><td>7a547_00000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 14:57:06,775\tINFO tune.py:945 -- Total run time: 14.67 seconds (14.63 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-04-26 14:57:06 (running for 00:00:14.64)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/16 CPUs, 0/2 GPUs\n",
      "Result logdir: /home/akbar/ray_results/train_mlp_2023-04-26_14-56-52\n",
      "Number of trials: 10/10 (10 TERMINATED)\n",
      "+-----------------------+------------+--------------------+-----------------+-------+--------+------------------+------------+\n",
      "| Trial name            | status     | loc                | hidden_size     |    lr |   iter |   total time (s) |   val_loss |\n",
      "|-----------------------+------------+--------------------+-----------------+-------+--------+------------------+------------|\n",
      "| train_mlp_7a547_00000 | TERMINATED | 10.7.44.21:1033366 | [75, 35, 15, 5] | 0.001 |   1000 |          6.8099  |  0.100491  |\n",
      "| train_mlp_7a547_00001 | TERMINATED | 10.7.44.21:1033427 | [75, 35, 15, 5] | 0.01  |   1000 |          7.99999 |  0.0604842 |\n",
      "| train_mlp_7a547_00002 | TERMINATED | 10.7.44.21:1033428 | [75, 35, 15, 5] | 0.01  |   1000 |          8.04021 |  0.0604842 |\n",
      "| train_mlp_7a547_00003 | TERMINATED | 10.7.44.21:1033429 | [50, 10]        | 0.01  |   1000 |          7.602   |  0.0571121 |\n",
      "| train_mlp_7a547_00004 | TERMINATED | 10.7.44.21:1033430 | [50]            | 0.005 |   1000 |          7.00819 |  0.0507341 |\n",
      "| train_mlp_7a547_00005 | TERMINATED | 10.7.44.21:1033431 | [75, 35, 15, 5] | 0.005 |   1000 |          8.075   |  0.167816  |\n",
      "| train_mlp_7a547_00006 | TERMINATED | 10.7.44.21:1033432 | [75, 35, 15, 5] | 0.01  |   1000 |          8.06835 |  0.0604842 |\n",
      "| train_mlp_7a547_00007 | TERMINATED | 10.7.44.21:1033433 | [50, 10]        | 0.01  |   1000 |          7.6427  |  0.0571121 |\n",
      "| train_mlp_7a547_00008 | TERMINATED | 10.7.44.21:1033434 | [60, 30, 5]     | 0.001 |   1000 |          7.94391 |  0.0577037 |\n",
      "| train_mlp_7a547_00009 | TERMINATED | 10.7.44.21:1033435 | [75, 35, 15, 5] | 0.005 |   1000 |          8.07015 |  0.167816  |\n",
      "+-----------------------+------------+--------------------+-----------------+-------+--------+------------------+------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"hidden_size\": tune.choice([[50],[50,10], [75,35,15,5],[60,30,5] ]),\n",
    "    # \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    'lr':tune.choice([0.01, 0.005, 0.001]),\n",
    "    # \"num_epochs\": tune.choice([2000])\n",
    "}\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "# Initialize Ray\n",
    "ray.init()\n",
    "\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_mlp,\n",
    "    config=config,\n",
    "    num_samples=10,\n",
    "    progress_reporter=tune.CLIReporter()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config: {'hidden_size': [50], 'lr': 0.005}\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters found by Ray Tune\n",
    "best_config = analysis.get_best_config(metric=\"val_loss\", mode=\"min\")\n",
    "print(\"Best config:\", best_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config= {'hidden_size': [50], 'lr': 0.005}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import torch.utils.tensorboard as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir  = 'D:\\iitgn\\Thesis\\Spiro_Mask2'\n",
    "LOGGER = tb.SummaryWriter(log_dir + '/train', flush_secs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Train Loss: 10.3959, Val Loss: 11.1884\n",
      "Epoch [200/200], Train Loss: 0.0545, Val Loss: 0.0951\n",
      "val_loss 0.09511382132768631\n",
      "MSE Test Loss: 0.0287\n",
      "MAPE Test Loss: 5.1128\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "torch.manual_seed(42)\n",
    "# Define the model\n",
    "model = MLP(input_size=X_train.shape[1], hidden_sizes=best_config[\"hidden_size\"], output_size=1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_config[\"lr\"])\n",
    "\n",
    "# Train and validate the model\n",
    "# num_epochs = 5000\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "num_epochs = 200 \n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    LOGGER.add_scalar('Train Loss', loss, epoch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # train_losses.append(loss.item())\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val)\n",
    "        val_loss = criterion(outputs, y_val)\n",
    "        # val_losses.append(loss.item())\n",
    "\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            torch.save(model.state_dict(), 'best_model_hyper.pt') \n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1 ==1) or (epoch+1) % 200 == 0:\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item(), val_loss.item()))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "model.load_state_dict(torch.load('best_model_hyper.pt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print('val_loss', criterion(model(X_val), y_val).item())\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test)\n",
    "    print('MSE Test Loss: {:.4f}'.format(test_loss.item()))\n",
    "    print('MAPE Test Loss: {:.4f}'.format(mape_loss(y_pred, y_test).item())) \n",
    "\n",
    "# Close the SummaryWriter instance\n",
    "LOGGER.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2132), started 8:07:10 ago. (Use '!kill 2132' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-eee35a2953d68300\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-eee35a2953d68300\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=D:\\iitgn\\Thesis\\Spiro_Mask2\\train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
