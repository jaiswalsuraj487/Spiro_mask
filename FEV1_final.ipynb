{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import ray\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([38, 166]) torch.Size([38, 1])\n",
      "torch.Size([5, 166]) torch.Size([5, 1])\n",
      "torch.Size([5, 166]) torch.Size([5, 1])\n"
     ]
    }
   ],
   "source": [
    "X_train,X_val, X_test, y_train, y_val, y_test = load_data('FEV1')\n",
    "# print(X.shape, Y.shape)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 6.7897, Val Loss: 7.0684\n",
      "Epoch [100/500], Train Loss: 0.0878, Val Loss: 0.0684\n",
      "Epoch [200/500], Train Loss: 0.0588, Val Loss: 0.0704\n",
      "Epoch [300/500], Train Loss: 0.0350, Val Loss: 0.1180\n",
      "Epoch [400/500], Train Loss: 0.0141, Val Loss: 0.2402\n",
      "Epoch [500/500], Train Loss: 0.0052, Val Loss: 0.3306\n",
      "val_loss 0.06285937875509262\n",
      "MSE Test Loss: 0.1120\n",
      "MAPE Test Loss: 9.1002\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(42)\n",
    "# Define model, loss function, and optimizer\n",
    "model = MLP(input_size=X_train.shape[1], hidden_sizes=[75,35,15,5], output_size=1)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
    "\n",
    "# Train and validate the model\n",
    "num_epochs = 500\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "ep =0\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # train_losses.append(loss.item())\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val)\n",
    "        val_loss = criterion(outputs, y_val)\n",
    "        # val_losses.append(loss.item())\n",
    "\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            ep = epoch\n",
    "            torch.save(model.state_dict(), 'best_model.pt') \n",
    "\n",
    "    if (epoch+1 ==1) or (epoch+1) % 100 == 0:\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item(), val_loss.item()))\n",
    "\n",
    "# Evaluate \n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print('val_loss', criterion(model(X_val), y_val).item())\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test)\n",
    "    print('MSE Test Loss: {:.4f}'.format(test_loss.item()))\n",
    "    print('MAPE Test Loss: {:.4f}'.format(mape_loss(y_pred, y_test).item())) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.01642843708395958"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "def train_mlp(config, checkpoint_dir=None):\n",
    "    X_train,X_val, X_test, y_train, y_val, y_test = load_data('FVC')\n",
    "    best_val_loss = float('inf')\n",
    "\n",
    "    model = MLP(input_size=X_train.shape[1], hidden_sizes=config[\"hidden_size\"], output_size=1)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"lr\"])\n",
    "    num_epochs = 50\n",
    "    for epoch in range(num_epochs):\n",
    "      # Training\n",
    "      model.train()\n",
    "      outputs = model(X_train)\n",
    "      loss = criterion(outputs, y_train)\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      tune.report(loss=loss.item())\n",
    "      # Validation\n",
    "      model.eval()\n",
    "      with torch.no_grad():\n",
    "            outputs = model(X_val)\n",
    "            val_loss = criterion(outputs, y_val)\n",
    "            if val_loss.item() < best_val_loss:\n",
    "                best_val_loss = val_loss\n",
    "\n",
    "      # tune.report(val_loss = best_val_loss)\n",
    "      # tune.report(val_loss = val_loss.item())\n",
    "      tune.report(best_val_loss = best_val_loss.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 15:09:45,120\tINFO worker.py:1625 -- Started a local Ray instance.\n",
      "2023-04-26 15:09:46,016\tWARNING callback.py:142 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-04-26 15:09:48 (running for 00:00:02.97)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 1.0/16 CPUs, 0/2 GPUs\n",
      "Result logdir: /home/akbar/ray_results/train_mlp_2023-04-26_15-09-46\n",
      "Number of trials: 10/10 (9 PENDING, 1 RUNNING)\n",
      "+-----------------------+----------+--------------------+-----------------+-------+\n",
      "| Trial name            | status   | loc                | hidden_size     |    lr |\n",
      "|-----------------------+----------+--------------------+-----------------+-------|\n",
      "| train_mlp_479bb_00000 | RUNNING  | 10.7.44.21:1041780 | [75, 35, 15, 5] | 0.01  |\n",
      "| train_mlp_479bb_00001 | PENDING  |                    | [50]            | 0.001 |\n",
      "| train_mlp_479bb_00002 | PENDING  |                    | [60, 30, 5]     | 0.01  |\n",
      "| train_mlp_479bb_00003 | PENDING  |                    | [50, 10]        | 0.01  |\n",
      "| train_mlp_479bb_00004 | PENDING  |                    | [75, 35, 15, 5] | 0.001 |\n",
      "| train_mlp_479bb_00005 | PENDING  |                    | [75, 35, 15, 5] | 0.005 |\n",
      "| train_mlp_479bb_00006 | PENDING  |                    | [60, 30, 5]     | 0.005 |\n",
      "| train_mlp_479bb_00007 | PENDING  |                    | [60, 30, 5]     | 0.001 |\n",
      "| train_mlp_479bb_00008 | PENDING  |                    | [50, 10]        | 0.01  |\n",
      "| train_mlp_479bb_00009 | PENDING  |                    | [50, 10]        | 0.001 |\n",
      "+-----------------------+----------+--------------------+-----------------+-------+\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>done  </th><th>hostname  </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>loss           </th><th>node_ip   </th><th style=\"text-align: right;\">    pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mlp_479bb_00000</td><td>2023-04-26_15-09-49</td><td>True  </td><td>cvig      </td><td style=\"text-align: right;\">                       100</td><td>               </td><td>10.7.44.21</td><td style=\"text-align: right;\">1041780</td><td style=\"text-align: right;\">           0.412217 </td><td style=\"text-align: right;\">        0.00250745</td><td style=\"text-align: right;\">     0.412217 </td><td style=\"text-align: right;\"> 1682501989</td><td style=\"text-align: right;\">                 100</td><td>479bb_00000</td></tr>\n",
       "<tr><td>train_mlp_479bb_00008</td><td>2023-04-26_15-09-52</td><td>False </td><td>cvig      </td><td style=\"text-align: right;\">                         1</td><td>9.7188138961792</td><td>10.7.44.21</td><td style=\"text-align: right;\">1041853</td><td style=\"text-align: right;\">           0.0530739</td><td style=\"text-align: right;\">        0.0530739 </td><td style=\"text-align: right;\">     0.0530739</td><td style=\"text-align: right;\"> 1682501992</td><td style=\"text-align: right;\">                   1</td><td>479bb_00008</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-26 15:09:53,606\tINFO tune.py:945 -- Total run time: 7.62 seconds (7.56 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-04-26 15:09:53 (running for 00:00:07.58)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/16 CPUs, 0/2 GPUs\n",
      "Result logdir: /home/akbar/ray_results/train_mlp_2023-04-26_15-09-46\n",
      "Number of trials: 10/10 (10 TERMINATED)\n",
      "+-----------------------+------------+--------------------+-----------------+-------+--------+------------------+-----------------+\n",
      "| Trial name            | status     | loc                | hidden_size     |    lr |   iter |   total time (s) |   best_val_loss |\n",
      "|-----------------------+------------+--------------------+-----------------+-------+--------+------------------+-----------------|\n",
      "| train_mlp_479bb_00000 | TERMINATED | 10.7.44.21:1041780 | [75, 35, 15, 5] | 0.01  |    100 |         0.412217 |       0.0263909 |\n",
      "| train_mlp_479bb_00001 | TERMINATED | 10.7.44.21:1041846 | [50]            | 0.001 |    100 |         0.787838 |       8.40317   |\n",
      "| train_mlp_479bb_00002 | TERMINATED | 10.7.44.21:1041847 | [60, 30, 5]     | 0.01  |    100 |         0.745824 |       0.0272229 |\n",
      "| train_mlp_479bb_00003 | TERMINATED | 10.7.44.21:1041848 | [50, 10]        | 0.01  |    100 |         0.739166 |       0.0307787 |\n",
      "| train_mlp_479bb_00004 | TERMINATED | 10.7.44.21:1041849 | [75, 35, 15, 5] | 0.001 |    100 |         0.823858 |      10.0873    |\n",
      "| train_mlp_479bb_00005 | TERMINATED | 10.7.44.21:1041850 | [75, 35, 15, 5] | 0.005 |    100 |         0.818788 |       0.713055  |\n",
      "| train_mlp_479bb_00006 | TERMINATED | 10.7.44.21:1041851 | [60, 30, 5]     | 0.005 |    100 |         0.871781 |       0.169573  |\n",
      "| train_mlp_479bb_00007 | TERMINATED | 10.7.44.21:1041852 | [60, 30, 5]     | 0.001 |    100 |         1.00349  |       7.72309   |\n",
      "| train_mlp_479bb_00008 | TERMINATED | 10.7.44.21:1041853 | [50, 10]        | 0.01  |    100 |         1.02689  |       0.0307787 |\n",
      "| train_mlp_479bb_00009 | TERMINATED | 10.7.44.21:1041854 | [50, 10]        | 0.001 |    100 |         0.893309 |       8.15071   |\n",
      "+-----------------------+------------+--------------------+-----------------+-------+--------+------------------+-----------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = {\n",
    "    \"hidden_size\": tune.choice([[50],[50,10], [75,35,15,5],[60,30,5] ]),\n",
    "    # \"lr\": tune.loguniform(1e-5, 1e-1),\n",
    "    'lr':tune.choice([0.01, 0.005, 0.001]),\n",
    "    # \"num_epochs\": tune.choice([2000])\n",
    "}\n",
    "\n",
    "\n",
    "ray.shutdown()\n",
    "# Initialize Ray\n",
    "ray.init()\n",
    "\n",
    "\n",
    "analysis = tune.run(\n",
    "    train_mlp,\n",
    "    config=config,\n",
    "    num_samples=10,\n",
    "    progress_reporter=tune.CLIReporter()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config: {'hidden_size': [75, 35, 15, 5], 'lr': 0.01}\n"
     ]
    }
   ],
   "source": [
    "# Print the best hyperparameters found by Ray Tune\n",
    "best_config = analysis.get_best_config(metric=\"best_val_loss\", mode=\"min\")\n",
    "print(\"Best config:\", best_config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config = {'hidden_size': [75, 35, 15, 5], 'lr': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import torch.utils.tensorboard as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir  = 'D:\\iitgn\\Thesis\\Spiro_Mask2'\n",
    "LOGGER = tb.SummaryWriter(log_dir + '/train_fev1', flush_secs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200], Train Loss: 6.7897, Val Loss: 6.9958\n",
      "Epoch [10/200], Train Loss: 4.1150, Val Loss: 4.1562\n",
      "Epoch [20/200], Train Loss: 1.2169, Val Loss: 1.3173\n",
      "Epoch [30/200], Train Loss: 0.3808, Val Loss: 0.2103\n",
      "Epoch [40/200], Train Loss: 0.2164, Val Loss: 0.3280\n",
      "Epoch [50/200], Train Loss: 0.1328, Val Loss: 0.0829\n",
      "Epoch [60/200], Train Loss: 0.1044, Val Loss: 0.1358\n",
      "Epoch [70/200], Train Loss: 0.0932, Val Loss: 0.0902\n",
      "Epoch [80/200], Train Loss: 0.0843, Val Loss: 0.0728\n",
      "Epoch [90/200], Train Loss: 0.0782, Val Loss: 0.0678\n",
      "Epoch [100/200], Train Loss: 0.0722, Val Loss: 0.0684\n",
      "Epoch [110/200], Train Loss: 0.0676, Val Loss: 0.0666\n",
      "Epoch [120/200], Train Loss: 0.0632, Val Loss: 0.0673\n",
      "Epoch [130/200], Train Loss: 0.0591, Val Loss: 0.0683\n",
      "Epoch [140/200], Train Loss: 0.0551, Val Loss: 0.0690\n",
      "Epoch [150/200], Train Loss: 0.0514, Val Loss: 0.0677\n",
      "Epoch [160/200], Train Loss: 0.0478, Val Loss: 0.0667\n",
      "Epoch [170/200], Train Loss: 0.0442, Val Loss: 0.0654\n",
      "Epoch [180/200], Train Loss: 0.0408, Val Loss: 0.0655\n",
      "Epoch [190/200], Train Loss: 0.0373, Val Loss: 0.0663\n",
      "Epoch [200/200], Train Loss: 0.0337, Val Loss: 0.0693\n",
      "val_loss 0.06477993726730347\n",
      "MSE Test Loss: 0.0596\n",
      "MAPE Test Loss: 7.0917\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "torch.manual_seed(42)\n",
    "# Define the model\n",
    "model = MLP(input_size=X_train.shape[1], hidden_sizes=best_config[\"hidden_size\"], output_size=1)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=best_config[\"lr\"])\n",
    "\n",
    "# Train and validate the model\n",
    "# num_epochs = 5000\n",
    "# train_losses = []\n",
    "# val_losses = []\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    # Training\n",
    "    model.train()\n",
    "    outputs = model(X_train)\n",
    "    loss = criterion(outputs, y_train)\n",
    "    LOGGER.add_scalar('Train Loss', loss, epoch)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    # train_losses.append(loss.item())\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        outputs = model(X_val)\n",
    "        val_loss = criterion(outputs, y_val)\n",
    "        # val_losses.append(loss.item())\n",
    "\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            torch.save(model.state_dict(), 'best_model_hyper.pt') \n",
    "    \n",
    "    # Print progress\n",
    "    if (epoch+1 ==1) or (epoch+1) % 10 == 0:\n",
    "        print('Epoch [{}/{}], Train Loss: {:.4f}, Val Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item(), val_loss.item()))\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "model.load_state_dict(torch.load('best_model_hyper.pt'))\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    print('val_loss', criterion(model(X_val), y_val).item())\n",
    "    y_pred = model(X_test)\n",
    "    test_loss = criterion(y_pred, y_test)\n",
    "    print('MSE Test Loss: {:.4f}'.format(test_loss.item()))\n",
    "    print('MAPE Test Loss: {:.4f}'.format(mape_loss(y_pred, y_test).item())) \n",
    "\n",
    "# Close the SummaryWriter instance\n",
    "LOGGER.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 2132), started 1:00:16 ago. (Use '!kill 2132' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-efe6455eae7e89cb\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-efe6455eae7e89cb\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=D:\\iitgn\\Thesis\\Spiro_Mask2\\train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
