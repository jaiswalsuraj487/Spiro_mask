{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utils.py loaded\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import ray\n",
    "from ray import tune"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning y and var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 5.0578, Val Loss: 5.2345\n",
      "Epoch [100/500], Train Loss: -0.2741, Val Loss: 70.3601\n",
      "Epoch [200/500], Train Loss: -0.5554, Val Loss: 986.8797\n",
      "Epoch [300/500], Train Loss: -0.9224, Val Loss: 16724.0332\n",
      "Epoch [400/500], Train Loss: -0.6181, Val Loss: 74.5441\n",
      "Epoch [500/500], Train Loss: -0.8872, Val Loss: 1469.0956\n",
      "val loss at Epoch :  49\n",
      "MAPE val:  4.192838668823242\n",
      "MSE val:  0.03468561917543411\n",
      "Loss tfp val:  0.20116481184959412\n",
      "MAPE test:  6.219310760498047\n",
      "MSE test:  0.04740426689386368\n",
      "Loss tfp test:  0.5905280709266663\n"
     ]
    }
   ],
   "source": [
    "output_2_fvc = model_run(file_name = 'FVC', num_epochs= 500, hidden_sizes =  [50,10], output_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.8091],\n",
       "         [3.0718],\n",
       "         [3.2758],\n",
       "         [3.2628],\n",
       "         [3.1932]]),\n",
       " tensor([[-1.2952],\n",
       "         [-1.4084],\n",
       "         [-1.5517],\n",
       "         [-1.5378],\n",
       "         [-1.4968]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2_fvc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 4.2035, Val Loss: 3.5175\n",
      "Epoch [100/500], Train Loss: 0.4302, Val Loss: 0.4227\n",
      "Epoch [200/500], Train Loss: 1.2654, Val Loss: 0.8331\n",
      "Epoch [300/500], Train Loss: -0.4932, Val Loss: 0.0698\n",
      "Epoch [400/500], Train Loss: 1.1664, Val Loss: 0.9314\n",
      "Epoch [500/500], Train Loss: 0.0824, Val Loss: 0.2650\n",
      "val loss at Epoch :  189\n",
      "MAPE val:  3.433788537979126\n",
      "MSE val:  0.019140856340527534\n",
      "Loss tfp val:  -0.6632509231567383\n",
      "MAPE test:  10.863091468811035\n",
      "MSE test:  0.12362875044345856\n",
      "Loss tfp test:  17.428630828857422\n"
     ]
    }
   ],
   "source": [
    "output_2_fev1 = model_run(file_name = 'FEV1', num_epochs= 500, hidden_sizes =  [50,10], output_size = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[2.6744],\n",
       "         [1.9241],\n",
       "         [3.0492],\n",
       "         [3.4553],\n",
       "         [2.7051]]),\n",
       " tensor([[-4.2114],\n",
       "         [-3.0975],\n",
       "         [-4.1102],\n",
       "         [-4.8354],\n",
       "         [-2.3073]]))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_2_fev1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 10.2448, Val Loss: 11.1006\n",
      "Epoch [100/500], Train Loss: 0.0622, Val Loss: 0.0490\n",
      "Epoch [200/500], Train Loss: 0.0489, Val Loss: 0.0920\n",
      "Epoch [300/500], Train Loss: 0.0441, Val Loss: 0.0877\n",
      "Epoch [400/500], Train Loss: 0.0414, Val Loss: 0.0790\n",
      "Epoch [500/500], Train Loss: 0.0396, Val Loss: 0.0704\n",
      "val loss at Epoch :  66\n",
      "MAPE val:  3.0852341651916504\n",
      "MSE val:  0.01854533888399601\n",
      "MAPE test:  8.039169311523438\n",
      "MSE test:  0.06806212663650513\n"
     ]
    }
   ],
   "source": [
    "output_1_fvc = model_run(file_name = 'FVC', num_epochs= 500, hidden_sizes =  [50,10], output_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.8411],\n",
       "        [3.1889],\n",
       "        [3.3528],\n",
       "        [3.4241],\n",
       "        [3.2285]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1_fvc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 10.9925, Val Loss: 9.5414\n",
      "Epoch [100/500], Train Loss: 0.0820, Val Loss: 0.1371\n",
      "Epoch [200/500], Train Loss: 0.0274, Val Loss: 0.8322\n",
      "Epoch [300/500], Train Loss: 0.0202, Val Loss: 0.7312\n",
      "Epoch [400/500], Train Loss: 0.0155, Val Loss: 0.5251\n",
      "Epoch [500/500], Train Loss: 0.0088, Val Loss: 0.5968\n",
      "val loss at Epoch :  43\n",
      "MAPE val:  4.456958770751953\n",
      "MSE val:  0.02602154016494751\n",
      "MAPE test:  9.542654991149902\n",
      "MSE test:  0.11077382415533066\n"
     ]
    }
   ],
   "source": [
    "output_1_fev1 = model_run(file_name = 'FEV1', num_epochs= 500, hidden_sizes =  [50,10], output_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.6744],\n",
       "        [2.0870],\n",
       "        [3.1219],\n",
       "        [3.2695],\n",
       "        [2.8194]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_1_fev1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"hidden_size\": tune.choice([[50,10] ,[60,30,5], [75,35,15,5],[128,80,50,30,16]]),\n",
    "    'lr':tune.choice([0.01, 0.001]),\n",
    "    \"num_epochs\": tune.choice([2000])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config_fvc_out2 = {'hidden_size': [75, 35, 15, 5], 'lr': 0.001, 'num_epochs': 2000}\n",
    "best_config_fev1_out2 = {'hidden_size': [75, 35, 15, 5], 'lr': 0.01, 'num_epochs': 2000}\n",
    "best_config_fvc_out1 = {'hidden_size': [60, 30, 5], 'lr': 0.01, 'num_epochs': 2000}        \n",
    "best_config_fev1_out1 = {'hidden_size': [128, 80, 50, 30, 16], 'lr': 0.001, 'num_epochs': 2000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000], Train Loss: 6.0961, Val Loss: 6.7044\n",
      "Epoch [100/2000], Train Loss: 2.1513, Val Loss: 2.4245\n",
      "Epoch [200/2000], Train Loss: 1.3433, Val Loss: 1.3674\n",
      "Epoch [300/2000], Train Loss: 0.7230, Val Loss: 0.7421\n",
      "Epoch [400/2000], Train Loss: -0.1157, Val Loss: 3.7265\n",
      "Epoch [500/2000], Train Loss: -0.2032, Val Loss: 5.3934\n",
      "Epoch [600/2000], Train Loss: -0.2553, Val Loss: 8.0654\n",
      "Epoch [700/2000], Train Loss: -0.3398, Val Loss: 14.3098\n",
      "Epoch [800/2000], Train Loss: -0.4875, Val Loss: 92.6303\n",
      "Epoch [900/2000], Train Loss: -0.6391, Val Loss: 815.2264\n",
      "Epoch [1000/2000], Train Loss: -0.7994, Val Loss: 6770.7720\n",
      "Epoch [1100/2000], Train Loss: -0.9263, Val Loss: 13821.8809\n",
      "Epoch [1200/2000], Train Loss: -1.0524, Val Loss: 24083.0977\n",
      "Epoch [1300/2000], Train Loss: -1.2094, Val Loss: 52720.2109\n",
      "Epoch [1400/2000], Train Loss: -1.2855, Val Loss: 48187.1641\n",
      "Epoch [1500/2000], Train Loss: -1.5151, Val Loss: 110016.9844\n",
      "Epoch [1600/2000], Train Loss: -1.6239, Val Loss: 108894.8516\n",
      "Epoch [1700/2000], Train Loss: -1.7070, Val Loss: 123718.5469\n",
      "Epoch [1800/2000], Train Loss: -1.5669, Val Loss: 147182.0469\n",
      "Epoch [1900/2000], Train Loss: -1.7793, Val Loss: 94552.4844\n",
      "Epoch [2000/2000], Train Loss: -1.9198, Val Loss: 135751.0312\n",
      "val loss at Epoch :  325\n",
      "MAPE val:  7.140254020690918\n",
      "MSE val:  0.11682698875665665\n",
      "Loss tfp val:  0.610312283039093\n",
      "MAPE test:  5.188878536224365\n",
      "MSE test:  0.03634323924779892\n",
      "Loss tfp test:  1.269187331199646\n"
     ]
    }
   ],
   "source": [
    "output_2_fvc = model_run(file_name = 'FVC', num_epochs= best_config_fvc_out2['num_epochs'], hidden_sizes =  best_config_fvc_out2['hidden_size'], output_size = 2, lr = best_config_fvc_out2['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000], Train Loss: 5.9789, Val Loss: 5.9104\n",
      "Epoch [100/2000], Train Loss: 1.4132, Val Loss: 1.4002\n",
      "Epoch [200/2000], Train Loss: 4.3549, Val Loss: 4.4995\n",
      "Epoch [300/2000], Train Loss: -0.3326, Val Loss: 0.6809\n",
      "Epoch [400/2000], Train Loss: -0.2092, Val Loss: 0.3909\n",
      "Epoch [500/2000], Train Loss: -0.3758, Val Loss: -0.0530\n",
      "Epoch [600/2000], Train Loss: 1.1036, Val Loss: 6.4166\n",
      "Epoch [700/2000], Train Loss: 0.9856, Val Loss: 1.6015\n",
      "Epoch [800/2000], Train Loss: -0.5159, Val Loss: 0.0710\n",
      "Epoch [900/2000], Train Loss: -1.1755, Val Loss: 3.2250\n",
      "Epoch [1000/2000], Train Loss: -0.5053, Val Loss: 1.0358\n",
      "Epoch [1100/2000], Train Loss: -1.1795, Val Loss: 66.8696\n",
      "Epoch [1200/2000], Train Loss: -1.2377, Val Loss: 194.0685\n",
      "Epoch [1300/2000], Train Loss: 5.9887, Val Loss: 3.6114\n",
      "Epoch [1400/2000], Train Loss: -1.0216, Val Loss: 5.6423\n",
      "Epoch [1500/2000], Train Loss: -0.2138, Val Loss: 0.1450\n",
      "Epoch [1600/2000], Train Loss: -0.6145, Val Loss: 0.6199\n",
      "Epoch [1700/2000], Train Loss: -0.8178, Val Loss: 1.6739\n",
      "Epoch [1800/2000], Train Loss: -0.7047, Val Loss: 3.2182\n",
      "Epoch [1900/2000], Train Loss: -1.1736, Val Loss: 4.1567\n",
      "Epoch [2000/2000], Train Loss: -1.1571, Val Loss: 4.3211\n",
      "val loss at Epoch :  311\n",
      "MAPE val:  5.158702373504639\n",
      "MSE val:  0.027920249849557877\n",
      "Loss tfp val:  -0.3933677077293396\n",
      "MAPE test:  10.298738479614258\n",
      "MSE test:  0.12637528777122498\n",
      "Loss tfp test:  1.3070135116577148\n"
     ]
    }
   ],
   "source": [
    "output_2_fev1 = model_run(file_name = 'FEV1', num_epochs= best_config_fev1_out2['num_epochs'], hidden_sizes =  best_config_fev1_out2['hidden_size'], output_size = 2, lr = best_config_fev1_out2['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000], Train Loss: 8.7189, Val Loss: 9.3833\n",
      "Epoch [100/2000], Train Loss: 0.0557, Val Loss: 0.0428\n",
      "Epoch [200/2000], Train Loss: 0.0441, Val Loss: 0.0553\n",
      "Epoch [300/2000], Train Loss: 0.0400, Val Loss: 0.0629\n",
      "Epoch [400/2000], Train Loss: 0.0379, Val Loss: 0.0702\n",
      "Epoch [500/2000], Train Loss: 0.0363, Val Loss: 0.0838\n",
      "Epoch [600/2000], Train Loss: 0.0349, Val Loss: 0.1008\n",
      "Epoch [700/2000], Train Loss: 0.0332, Val Loss: 0.1195\n",
      "Epoch [800/2000], Train Loss: 0.0313, Val Loss: 0.1472\n",
      "Epoch [900/2000], Train Loss: 0.0292, Val Loss: 0.1897\n",
      "Epoch [1000/2000], Train Loss: 0.0271, Val Loss: 0.1984\n",
      "Epoch [1100/2000], Train Loss: 0.0176, Val Loss: 0.0310\n",
      "Epoch [1200/2000], Train Loss: 0.0097, Val Loss: 0.0356\n",
      "Epoch [1300/2000], Train Loss: 0.0077, Val Loss: 0.0551\n",
      "Epoch [1400/2000], Train Loss: 0.0073, Val Loss: 0.0474\n",
      "Epoch [1500/2000], Train Loss: 0.0047, Val Loss: 0.0466\n",
      "Epoch [1600/2000], Train Loss: 0.0039, Val Loss: 0.0325\n",
      "Epoch [1700/2000], Train Loss: 0.0035, Val Loss: 0.0783\n",
      "Epoch [1800/2000], Train Loss: 0.0032, Val Loss: 0.2834\n",
      "Epoch [1900/2000], Train Loss: 0.0030, Val Loss: 0.4942\n",
      "Epoch [2000/2000], Train Loss: 0.0028, Val Loss: 0.6301\n",
      "val loss at Epoch :  57\n",
      "MAPE val:  3.6774072647094727\n",
      "MSE val:  0.020608562976121902\n",
      "MAPE test:  5.899529457092285\n",
      "MSE test:  0.048156093806028366\n"
     ]
    }
   ],
   "source": [
    "output_1_fvc = model_run(file_name = 'FVC', num_epochs= best_config_fvc_out1['num_epochs'], hidden_sizes =  best_config_fvc_out1['hidden_size'], output_size = 1, lr = best_config_fvc_out1['lr'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2000], Train Loss: 9.2454, Val Loss: 9.6518\n",
      "Epoch [100/2000], Train Loss: 0.1130, Val Loss: 0.1092\n",
      "Epoch [200/2000], Train Loss: 0.0477, Val Loss: 0.1248\n",
      "Epoch [300/2000], Train Loss: 0.0182, Val Loss: 0.2493\n",
      "Epoch [400/2000], Train Loss: 0.0069, Val Loss: 0.3521\n",
      "Epoch [500/2000], Train Loss: 0.0025, Val Loss: 0.3821\n",
      "Epoch [600/2000], Train Loss: 0.0007, Val Loss: 0.3603\n",
      "Epoch [700/2000], Train Loss: 0.0002, Val Loss: 0.3140\n",
      "Epoch [800/2000], Train Loss: 0.0001, Val Loss: 0.3126\n",
      "Epoch [900/2000], Train Loss: 0.0001, Val Loss: 0.3043\n",
      "Epoch [1000/2000], Train Loss: 0.0001, Val Loss: 0.3354\n",
      "Epoch [1100/2000], Train Loss: 0.0001, Val Loss: 0.3497\n",
      "Epoch [1200/2000], Train Loss: 0.0000, Val Loss: 0.3385\n",
      "Epoch [1300/2000], Train Loss: 0.0002, Val Loss: 0.3728\n",
      "Epoch [1400/2000], Train Loss: 0.0000, Val Loss: 0.3502\n",
      "Epoch [1500/2000], Train Loss: 0.0000, Val Loss: 0.3666\n",
      "Epoch [1600/2000], Train Loss: 0.0000, Val Loss: 0.3622\n",
      "Epoch [1700/2000], Train Loss: 0.0000, Val Loss: 0.2783\n",
      "Epoch [1800/2000], Train Loss: 0.0004, Val Loss: 0.3015\n",
      "Epoch [1900/2000], Train Loss: 0.0000, Val Loss: 0.2933\n",
      "Epoch [2000/2000], Train Loss: 0.0000, Val Loss: 0.3135\n",
      "val loss at Epoch :  56\n",
      "MAPE val:  8.467541694641113\n",
      "MSE val:  0.08505773544311523\n",
      "MAPE test:  9.465457916259766\n",
      "MSE test:  0.12938706576824188\n"
     ]
    }
   ],
   "source": [
    "output_1_fev1 = model_run(file_name = 'FEV1', num_epochs= best_config_fev1_out1['num_epochs'], hidden_sizes =  best_config_fev1_out1['hidden_size'], output_size = 1, lr = best_config_fev1_out1['lr'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fvc output 2\n",
    "# MAPE test:  5.872068405151367\n",
    "# tune:\n",
    "# MAPE test:  5.188878536224365\n",
    "\n",
    "\n",
    "# fev1 output 2\n",
    "# MAPE test:  10.863091468811035\n",
    "# tune :\n",
    "# MAPE test:  10.298738479614258\n",
    "\n",
    "\n",
    "# fvc output 1\n",
    "# MAPE test:  8.039169311523438\n",
    "# tune:\n",
    "# MAPE test:  5.899529457092285\n",
    "\n",
    "\n",
    "# fev1 output 1\n",
    "# MAPE test:  9.542654991149902\n",
    "# tune:\n",
    "# MAPE test:  9.465457916259766"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name           </th><th>date               </th><th>hostname       </th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  timestamp</th><th>trial_id   </th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mlp_102d9_00000</td><td>2023-05-04_09-44-11</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 3380</td><td style=\"text-align: right;\"> 1683173651</td><td>102d9_00000</td></tr>\n",
       "<tr><td>train_mlp_102d9_00001</td><td>2023-05-04_09-44-29</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\">22868</td><td style=\"text-align: right;\"> 1683173669</td><td>102d9_00001</td></tr>\n",
       "<tr><td>train_mlp_102d9_00002</td><td>2023-05-04_09-44-44</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\">14740</td><td style=\"text-align: right;\"> 1683173684</td><td>102d9_00002</td></tr>\n",
       "<tr><td>train_mlp_102d9_00003</td><td>2023-05-04_09-44-59</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 6188</td><td style=\"text-align: right;\"> 1683173699</td><td>102d9_00003</td></tr>\n",
       "<tr><td>train_mlp_102d9_00004</td><td>2023-05-04_09-45-17</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\">15876</td><td style=\"text-align: right;\"> 1683173717</td><td>102d9_00004</td></tr>\n",
       "<tr><td>train_mlp_102d9_00005</td><td>2023-05-04_09-45-44</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 8408</td><td style=\"text-align: right;\"> 1683173744</td><td>102d9_00005</td></tr>\n",
       "<tr><td>train_mlp_102d9_00006</td><td>2023-05-04_09-46-20</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\">  372</td><td style=\"text-align: right;\"> 1683173780</td><td>102d9_00006</td></tr>\n",
       "<tr><td>train_mlp_102d9_00007</td><td>2023-05-04_09-46-50</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\">18232</td><td style=\"text-align: right;\"> 1683173810</td><td>102d9_00007</td></tr>\n",
       "<tr><td>train_mlp_102d9_00008</td><td>2023-05-04_09-47-23</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 6276</td><td style=\"text-align: right;\"> 1683173843</td><td>102d9_00008</td></tr>\n",
       "<tr><td>train_mlp_102d9_00009</td><td>2023-05-04_09-47-23</td><td>DESKTOP-R44SHTF</td><td>127.0.0.1</td><td style=\"text-align: right;\">20704</td><td style=\"text-align: right;\"> 1683173843</td><td>102d9_00009</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [train_mlp_102d9_00000, train_mlp_102d9_00001, train_mlp_102d9_00002, train_mlp_102d9_00003, train_mlp_102d9_00004, train_mlp_102d9_00005, train_mlp_102d9_00006, train_mlp_102d9_00007, train_mlp_102d9_00008, train_mlp_102d9_00009])",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-8b6e00c76010>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0manalysis_fvc_out1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mraytune_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfile_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'FVC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32md:\\iitgn\\Thesis\\Spiro_Mask2\\utils.py\u001b[0m in \u001b[0;36mraytune_fun\u001b[1;34m(output_size, file_name)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# Initialize Ray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[0mray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m     analysis = tune.run(\n\u001b[0m\u001b[0;32m    189\u001b[0m             \u001b[0mtrain_mlp\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m             \u001b[0mconfig\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\ray\\tune\\tune.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, chdir_to_trial_dir, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, raise_on_failed_trial, callbacks, max_concurrent_trials, trial_executor, _experiment_checkpoint_dir, _remote, _remote_string_queue, _tuner_api)\u001b[0m\n\u001b[0;32m    937\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mexperiment_interrupted_event\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_set\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 939\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trials did not complete\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    940\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    941\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Trials did not complete: %s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mincomplete_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTuneError\u001b[0m: ('Trials did not complete', [train_mlp_102d9_00000, train_mlp_102d9_00001, train_mlp_102d9_00002, train_mlp_102d9_00003, train_mlp_102d9_00004, train_mlp_102d9_00005, train_mlp_102d9_00006, train_mlp_102d9_00007, train_mlp_102d9_00008, train_mlp_102d9_00009])"
     ]
    }
   ],
   "source": [
    "analysis_fvc_out1 = raytune_fun(output_size = 1, file_name='FVC') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_config_fvc = analysis_fvc_out1.get_best_config(metric=\"val_loss\", mode=\"min\")\n",
    "print(\"Best config:\", best_config_fvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name                    </th><th>date               </th><th>done  </th><th>experiment_tag                    </th><th>hostname       </th><th style=\"text-align: right;\">  iterations_since_restore</th><th>node_ip  </th><th style=\"text-align: right;\">  pid</th><th style=\"text-align: right;\">  time_since_restore</th><th style=\"text-align: right;\">  time_this_iter_s</th><th style=\"text-align: right;\">  time_total_s</th><th style=\"text-align: right;\">  timestamp</th><th style=\"text-align: right;\">  training_iteration</th><th>trial_id   </th><th style=\"text-align: right;\">  val_loss</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>train_mlp_output_1_6614e_00000</td><td>2023-05-03_23-30-49</td><td>True  </td><td>0_hidden_size=75_35_15_5,lr=0.0100</td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">21600</td><td style=\"text-align: right;\">           0.512657 </td><td style=\"text-align: right;\">         0.512657 </td><td style=\"text-align: right;\">     0.512657 </td><td style=\"text-align: right;\"> 1683136849</td><td style=\"text-align: right;\">                   1</td><td>6614e_00000</td><td style=\"text-align: right;\">   11.1893</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00001</td><td>2023-05-03_23-31-02</td><td>True  </td><td>1_hidden_size=75_35_15_5,lr=0.0100</td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">14260</td><td style=\"text-align: right;\">           0.0180161</td><td style=\"text-align: right;\">         0.0180161</td><td style=\"text-align: right;\">     0.0180161</td><td style=\"text-align: right;\"> 1683136862</td><td style=\"text-align: right;\">                   1</td><td>6614e_00001</td><td style=\"text-align: right;\">   11.1893</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00002</td><td>2023-05-03_23-31-14</td><td>True  </td><td>2_hidden_size=75_35_15_5,lr=0.0100</td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 1924</td><td style=\"text-align: right;\">           0.0215249</td><td style=\"text-align: right;\">         0.0215249</td><td style=\"text-align: right;\">     0.0215249</td><td style=\"text-align: right;\"> 1683136874</td><td style=\"text-align: right;\">                   1</td><td>6614e_00002</td><td style=\"text-align: right;\">   11.1893</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00003</td><td>2023-05-03_23-31-29</td><td>True  </td><td>3_hidden_size=50,lr=0.0100        </td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 3468</td><td style=\"text-align: right;\">           0.0140045</td><td style=\"text-align: right;\">         0.0140045</td><td style=\"text-align: right;\">     0.0140045</td><td style=\"text-align: right;\"> 1683136889</td><td style=\"text-align: right;\">                   1</td><td>6614e_00003</td><td style=\"text-align: right;\">   10.8933</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00004</td><td>2023-05-03_23-31-45</td><td>True  </td><td>4_hidden_size=75_35_15_5,lr=0.0100</td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">16884</td><td style=\"text-align: right;\">           0.0279961</td><td style=\"text-align: right;\">         0.0279961</td><td style=\"text-align: right;\">     0.0279961</td><td style=\"text-align: right;\"> 1683136905</td><td style=\"text-align: right;\">                   1</td><td>6614e_00004</td><td style=\"text-align: right;\">   11.1893</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00005</td><td>2023-05-03_23-31-59</td><td>True  </td><td>5_hidden_size=50_10,lr=0.0100     </td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 1372</td><td style=\"text-align: right;\">           0.0244927</td><td style=\"text-align: right;\">         0.0244927</td><td style=\"text-align: right;\">     0.0244927</td><td style=\"text-align: right;\"> 1683136919</td><td style=\"text-align: right;\">                   1</td><td>6614e_00005</td><td style=\"text-align: right;\">   10.3862</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00006</td><td>2023-05-03_23-32-16</td><td>True  </td><td>6_hidden_size=60_30_5,lr=0.0100   </td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\"> 7308</td><td style=\"text-align: right;\">           0.0174947</td><td style=\"text-align: right;\">         0.0174947</td><td style=\"text-align: right;\">     0.0174947</td><td style=\"text-align: right;\"> 1683136936</td><td style=\"text-align: right;\">                   1</td><td>6614e_00006</td><td style=\"text-align: right;\">   10.7365</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00007</td><td>2023-05-03_23-32-31</td><td>True  </td><td>7_hidden_size=50_10,lr=0.0100     </td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">22232</td><td style=\"text-align: right;\">           0.0175302</td><td style=\"text-align: right;\">         0.0175302</td><td style=\"text-align: right;\">     0.0175302</td><td style=\"text-align: right;\"> 1683136951</td><td style=\"text-align: right;\">                   1</td><td>6614e_00007</td><td style=\"text-align: right;\">   10.3862</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00008</td><td>2023-05-03_23-32-32</td><td>True  </td><td>8_hidden_size=50,lr=0.0001        </td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">21600</td><td style=\"text-align: right;\">           0.0139904</td><td style=\"text-align: right;\">         0.0139904</td><td style=\"text-align: right;\">     0.0139904</td><td style=\"text-align: right;\"> 1683136952</td><td style=\"text-align: right;\">                   1</td><td>6614e_00008</td><td style=\"text-align: right;\">   12.3452</td></tr>\n",
       "<tr><td>train_mlp_output_1_6614e_00009</td><td>2023-05-03_23-32-32</td><td>True  </td><td>9_hidden_size=60_30_5,lr=0.0100   </td><td>DESKTOP-R44SHTF</td><td style=\"text-align: right;\">                         1</td><td>127.0.0.1</td><td style=\"text-align: right;\">14260</td><td style=\"text-align: right;\">           0.0145195</td><td style=\"text-align: right;\">         0.0145195</td><td style=\"text-align: right;\">     0.0145195</td><td style=\"text-align: right;\"> 1683136952</td><td style=\"text-align: right;\">                   1</td><td>6614e_00009</td><td style=\"text-align: right;\">   10.0083</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 23:32:32,985\tINFO tune.py:945 -- Total run time: 119.70 seconds (119.46 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Current time: 2023-05-03 23:32:32 (running for 00:01:59.55)\n",
      "Using FIFO scheduling algorithm.\n",
      "Logical resource usage: 0/8 CPUs, 0/1 GPUs\n",
      "Result logdir: C:\\Users\\HP\\ray_results\\train_mlp_output_1_2023-05-03_23-30-33\n",
      "Number of trials: 10/10 (10 TERMINATED)\n",
      "+--------------------------------+------------+-----------------+-----------------+--------+--------+------------------+------------+\n",
      "| Trial name                     | status     | loc             | hidden_size     |     lr |   iter |   total time (s) |   val_loss |\n",
      "|--------------------------------+------------+-----------------+-----------------+--------+--------+------------------+------------|\n",
      "| train_mlp_output_1_6614e_00000 | TERMINATED | 127.0.0.1:21600 | [75, 35, 15, 5] | 0.01   |      1 |        0.512657  |    11.1893 |\n",
      "| train_mlp_output_1_6614e_00001 | TERMINATED | 127.0.0.1:14260 | [75, 35, 15, 5] | 0.01   |      1 |        0.0180161 |    11.1893 |\n",
      "| train_mlp_output_1_6614e_00002 | TERMINATED | 127.0.0.1:1924  | [75, 35, 15, 5] | 0.01   |      1 |        0.0215249 |    11.1893 |\n",
      "| train_mlp_output_1_6614e_00003 | TERMINATED | 127.0.0.1:3468  | [50]            | 0.01   |      1 |        0.0140045 |    10.8933 |\n",
      "| train_mlp_output_1_6614e_00004 | TERMINATED | 127.0.0.1:16884 | [75, 35, 15, 5] | 0.01   |      1 |        0.0279961 |    11.1893 |\n",
      "| train_mlp_output_1_6614e_00005 | TERMINATED | 127.0.0.1:1372  | [50, 10]        | 0.01   |      1 |        0.0244927 |    10.3862 |\n",
      "| train_mlp_output_1_6614e_00006 | TERMINATED | 127.0.0.1:7308  | [60, 30, 5]     | 0.01   |      1 |        0.0174947 |    10.7365 |\n",
      "| train_mlp_output_1_6614e_00007 | TERMINATED | 127.0.0.1:22232 | [50, 10]        | 0.01   |      1 |        0.0175302 |    10.3862 |\n",
      "| train_mlp_output_1_6614e_00008 | TERMINATED | 127.0.0.1:21600 | [50]            | 0.0001 |      1 |        0.0139904 |    12.3452 |\n",
      "| train_mlp_output_1_6614e_00009 | TERMINATED | 127.0.0.1:14260 | [60, 30, 5]     | 0.01   |      1 |        0.0145195 |    10.0083 |\n",
      "+--------------------------------+------------+-----------------+-----------------+--------+--------+------------------+------------+\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ray.shutdown()\n",
    "ray.init()\n",
    "analysis_fvc = tune.run( train_mlp_output_1,\n",
    "            config=config,\n",
    "            num_samples=10,\n",
    "            progress_reporter=tune.CLIReporter()\n",
    "        ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best config: {'hidden_size': [60, 30, 5], 'lr': 0.01}\n"
     ]
    }
   ],
   "source": [
    "best_config_fvc = analysis_fvc.get_best_config(metric=\"val_loss\", mode=\"min\")\n",
    "print(\"Best config:\", best_config_fvc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
